kibana:
  enabled: true
  elasticsearchHosts: "http://elasticsearch-client:9200"
  resources:
    requests:
      cpu: "500m"
      memory: "512Mi"
    limits:
      cpu: "1000m"
      memory: "1Gi"
  extraEnvs:
    - name: "NODE_OPTIONS"
      value: "--max-old-space-size=1800"
    - name: "LOGGING_QUIET"
      value: "false"

  updateStrategy:
    type: "RollingUpdate"

  service:
    type: NodePort 
    loadBalancerIP: ""
    port: 5601
    nodePort: "9100"
    labels: {}
    annotations: {}
    # cloud.google.com/load-balancer-type: "Internal"
    # service.beta.kubernetes.io/aws-load-balancer-internal: 0.0.0.0/0
    # service.beta.kubernetes.io/azure-load-balancer-internal: "true"
    # service.beta.kubernetes.io/openstack-internal-load-balancer: "true"
    # service.beta.kubernetes.io/cce-load-balancer-internal-vpc: "true"
    loadBalancerSourceRanges: []
    # 0.0.0.0/0
    httpPortName: http
  
  ingress:
    enabled: false
    annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
    path: /
    hosts:
      - chart-example.local
    tls: []
      #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

master:
  roles:
    master: "true"
    ingest: "false"
    data: "false"
  nodeGroup: "master"
  replicas: 1 
  minimumMasterNodes: 1
  esConfig: {}
  #  elasticsearch.yml: |
  #    path.repo: ["/usr/share/elasticsearch/data/backup"]
  #      nestedkey: value
  #  log4j2.properties: |
  #    key = value

  extraEnvs:
    - name: "XPACK_MONITORING_ENABLED"
      value: "true"

  esJavaOpts: "-Xmx1g -Xms1g"

  resources:
    requests:
      cpu: "1000m"
      memory: "1Gi"
    limits:
      cpu: "1000m"
      memory: "2Gi"

  # extraVolumes: |
  #   - name: "backup"
  #     nfs:
  #       server: yournfsserver
  #       path: /
  # extraVolumeMounts: |
  #   - name: backup
  #     mountPath: "/usr/share/elasticsearch/backup"

  volumeClaimTemplate:
    accessModes: ["ReadWriteOnce"]
    storageClassName: "local-path"
    resources:
      requests:
        storage: 4Gi

  sysctlInitContainer:
    enabled: false

data:
  roles:
    master: "false"
    ingest: "false"
    data: "true"
  nodeGroup: "data"
  replicas: 1 
  minimumMasterNodes: 1

  esConfig: {}
  #  elasticsearch.yml: |
  #    path.repo: ["/usr/share/elasticsearch/data/backup"]
  #      nestedkey: value
  #  log4j2.properties: |
  #    key = value

  extraEnvs:
    - name: "XPACK_MONITORING_ENABLED"
      value: "true"

  esJavaOpts: "-Xmx1536m -Xms1536m"

  resources:
    requests:
      cpu: "1000m"
      memory: "2Gi"
    limits:
      cpu: "1.5"
      memory: "3Gi"

  # extraVolumes: |
  #   - name: "backup"
  #     nfs:
  #       server: yournfsserver
  #       path: /
  # extraVolumeMounts: |
  #   - name: backup
  #     mountPath: "/usr/share/elasticsearch/backup"

  volumeClaimTemplate:
    accessModes: ["ReadWriteOnce"]
    storageClassName: "local-path"
    resources:
      requests:
        storage: 20Gi

  sysctlInitContainer:
    enabled: false

client:
  roles:
    master: "false"
    ingest: "true"
    data: "false"
  nodeGroup: "client"
  replicas: 1
  minimumMasterNodes: 1

  esConfig: {}
  #  elasticsearch.yml: |
  #    path.repo: ["/usr/share/elasticsearch/data/backup"]
  #      nestedkey: value
  #  log4j2.properties: |
  #    key = value

  extraEnvs:
    - name: "XPACK_MONITORING_ENABLED"
      value: "true"

  esJavaOpts: "-Xmx1g -Xms1g"

  resources:
    requests:
      cpu: "500m"
      memory: "1Gi"
    limits:
      cpu: "1.5"
      memory: "2Gi"

  # extraVolumes: |
    # - name: "backup"
    #   nfs:
    #     server: yournfsserver
    #     path: /
  # extraVolumeMounts: |
    # - name: backup
    #   mountPath: "/usr/share/elasticsearch/backup"

  persistence:
    enabled: false

logstash:
  enabled: true
  extraEnvs:
    - name: ELASTICSEARCH_HOST
      value: "elasticsearch-client"
    - name: ELASTICSEARCH_PORT
      value: "9200"

  logstashConfig:
    logstash.yml: |
      http.host: 0.0.0.0
      xpack.monitoring.elasticsearch.hosts: [ "http://elasticsearch-master:9200" ]

  logstashPipeline: 
   logstash.conf: |
      input {
        tcp {
          port => 5050
        }
        beats {
          port => 5044
        }
      }
      output {
        stdout {
           codec => rubydebug
        }
      }  
    
  extraPorts:
    - name: beats
      containerPort: 5044
    - name: tcpinput
      containerPort: 5050

  service:
    annotations: {}
    type: NodePort 
    ports:
      - name: beats
        port: 5044
        protocol: TCP
        targetPort: beats
        nodePort: 9144
      - name: tcpinput
        port: 5050
        protocol: TCP
        targetPort: tcpinput
        nodePort: 9150

  livenessProbe:
    initialDelaySeconds: 90

filebeat:
  enabled: true
  extraEnvs:
    - name: ELASTICSEARCH_HOST
      value: "elasticsearch-client"
    - name: ELASTICSEARCH_PORT
      value: "9200"
